---
title: "Regression"
author: "Micah Katz"
date: "2/17/2023"
output:
  pdf_document: default
  html_document:
    df_print: paged
editor_options:
  chunk_output_type: inline
---

## How Linear Regression Works

Linear Regression uses predictor variables and target variables. In Linear Regression, we need to find the specific relationship between the predictors and the target variables. Typically with a linear relationship, we can determine this with a slope of a line that correlates with the data points. The `lm()` function in R will allow us to make a linear model and the formula will allow us to set the predictors and the target variables. These are separated by a tilde (\~).

## Dataset

<https://www.kaggle.com/datasets/thedevastator/global-video-game-sales>

## Import Dataset

Here we are importing our Video Game Sales CSV file as `vgsales` to be used in our later code blocks.

```{r}
vgsales <- read.csv("vgsales.csv")
```

## Split into 80/20 training data

We split the data using the `sample()` function and make sure to split the data 80/20 between training and testing. We find the index to split the data on and assign it to `i` and then separate the data between training and testing.

```{r}
i <- sample(1:nrow(vgsales), 0.80*nrow(vgsales), replace=FALSE)
training <- vgsales[i, ]
testing <- vgsales[-i, ]
```

## Functions for data exploration

Here we are using different functions to explore the given data. `str()` will give us the structure of the data. `summary()` will give us a summary of the data. `hist()` will give us a histogram and we are plotting a histogram of the North America Sales. The `cor()` function will tell us the correlation of NA_Sales to EU_Sales. The `head()` function will show the first 6 rows of the training data.

```{r}
str(training)
summary(training)
hist(training$NA_Sales)
cor(training[,c("NA_Sales", "EU_Sales")])
head(training)
```

## Graphs for Data Exploration

We use `ggplot2` to graph a scatter plot of the training data of the North American Sales vs the Global Sales. We then plot a bar graph of Number of Video Games by Genre

```{r}
library(ggplot2)

ggplot(training, aes(x = NA_Sales, y = Global_Sales)) +
  geom_point() +
  labs(title = "North American Sales vs Global Sales",
       x = "North American Sales",
       y = "Global Sales")

ggplot(training, aes(x = Genre)) +
  geom_bar(fill = "blue") +
  labs(title = "Number of Video Games by Genre",
       x = "Genre",
       y = "Count")

```

## Linear Regression Model 1

This Linear Regression Model will take the `Global_Sales` as an X values, and `NA_Sales` as the Y values. We give the training data as well. We will later reference this linear regression model as `vgSalesModel`

```{r}
vgSalesModel <- lm(Global_Sales ~ NA_Sales, data = training)

summary(vgSalesModel)
```

### Plotting Residuals

We are plotting the residuals of the `vgSalesModel` using the `plot` function. We create a plot for the Residuals vs the Fitted Values. This comes from the `1` passed to the `which` parameter

```{r}
plot(vgSalesModel, which = 1)
```

## Linear Regression Model 2 (Multiple Linear Regression Model)

Here we are building a multiple linear regression model. The formula specified in the `lm()` function call includes `Global_Sales` as a response variable and the rest of the values as predictor variables. We are predicting what the Global Sales will be using the variables `NA_Sales` `EU_Sales` `JP_Sales` and `Other_Sales`

```{r}
vgSalesMultiModel <- lm(Global_Sales ~ Year + NA_Sales, data = training)

summary(vgSalesMultiModel)
```

### Plot Residuals

We are plotting the residuals of the `vgSalesMultiModel` using the `plot` function. We create a plot for the Residuals vs the Fitted Values and the Normal Q-Q plot. These come from the `c(1,3)` values passed to the `which` parameter

```{r}
plot(vgSalesMultiModel, which = c(1,3))
```

## Linear Regression Model 3

Here we are building a multiple linear regression model. The formula specified in the `lm()` function call includes `Global_Sales` as a response variable and the rest of the values as predictor variables. We are predicting what the Global Sales will be using the variables `NA_Sales` `Year` and `Genre`. We are then stating that the `Year` should vary based on the `Genre` by doing `Year*Genre`

```{r}
vgSalesModel3 <- lm(Global_Sales ~ NA_Sales + Year*Genre, data = training)

summary(vgSalesModel3)
```

### Plot Residuals

We are plotting the residuals of the `vgSalesModel3` using the `plot` function. We create a plot for the Residuals vs the Fitted Values, the Normal Q-Q plot, and the `Scale-Location Plot`. These come from the `c(1,2,3)` values passed to the `which` parameter

```{r}
plot(vgSalesModel3, which = c(1, 2, 3))
```

## Comparing the Models

When comparing the three models, it is clear that Linear Regression Model 3 is the best model. This is due to the R value being `0.8745` as compared to the other R values. I believe that by stating that the `Year` should vary based on the `Genre` by doing `Year*Genre` in the third model, we get the better R-value. As for the other models, it makes sense that the less complicated the formula, the less the R value is. I believe that this is due to the fact that there is so much data and the release year would typically affect the global sales.

## Predicting the Models

```{r}
pred1 <- predict(vgSalesModel, newdata = testing)
pred2 <- predict(vgSalesMultiModel, newdata = testing)
pred3 <- predict(vgSalesModel3, newdata = testing)

cor1 <- cor(testing$Global_Sales, pred1)
cor2 <- cor(testing$Global_Sales, pred2)
cor3 <- cor(testing$Global_Sales, pred3)

mse1 <- mean((testing$Global_Sales - pred1)^2)
mse2 <- mean((testing$Global_Sales - pred2)^2)
mse3 <- mean((testing$Global_Sales - pred3)^2)

cat("\n")
cat("Model 1 Correlation:", cor1, "MSE:", mse1, "\n")
cat("Model 2 Correlation:", cor2, "MSE:", mse2, "\n")
cat("Model 3 Correlation:", cor3, "MSE:", mse3, "\n")
```

From this output, we can see that the highest correlation is model 1. This might be because of the linear relation between North America Sales and Global Sales. The next highest correlation is model 2. This might be because there are different independent variables like Year and Genre. The lowest correlation is model 3. This might be because of the complexity of the formula that is somewhat non-linear. As for the MSE values, they were the opposite of the correlation. The lowest was model 1 and highest was model 3.
